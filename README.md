# gpuhackathon-sleap

This repo contains some stuff we did during the [Princeton GPU Hackathon 2021](https://gpuhackathons.org/index.php/event/princeton-gpu-hackathon-2021) working on ways to decrease inference latency in [SLEAP](https://sleap.ai).


- [`tensorrt`](tensorrt/README.md): A setup for running SLEAP models using TensorRT acceleration.

- [`triton`](triton/README.md): A simple example setup for using [Triton Inference Server](https://github.com/triton-inference-server/server) to serve SLEAP models.
